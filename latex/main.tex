\documentclass[conference]{IEEEtran}

% ----------------------------
% Packages
% ----------------------------
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}

% ----------------------------
% PDF metadata + hyperlinks
% ----------------------------
\hypersetup{
    pdftitle={RIC: A Solver-Observable Proxy for Proof-Theoretic SAT Hardness},
    pdfauthor={Nizar Amama},
    pdfsubject={SAT Hardness Prediction, Proof Complexity, Solver Dynamics},
    pdfkeywords={SAT, hardness prediction, proof complexity, solver-observable proxy, information theory, treewidth, CDCL},
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% ----------------------------
% Title & Author
% ----------------------------
\title{RIC: A Solver-Observable Proxy for Proof-Theoretic SAT Hardness}

\author{
\IEEEauthorblockN{Nizar Amama}
\IEEEauthorblockA{
Independent Researcher\\
ORCID: \href{https://orcid.org/0009-0004-6721-1117}{0009-0004-6721-1117}\\
Email: amamanizar@gmail.com
}
}

\begin{document}
\maketitle

\noindent\textbf{Preprint (Zenodo v2):} \href{https://doi.org/10.5281/zenodo.17968982}{10.5281/zenodo.17968982}

% ----------------------------
% Abstract
% ----------------------------
\begin{abstract}
Structural hardness measures for Boolean satisfiability---such as treewidth, backdoor size, and community structure---often capture closely related aspects of constraint-graph topology, and are frequently highly intercorrelated in practice. This redundancy limits their ability to characterize the full spectrum of SAT instance difficulty.

We introduce \textbf{RIC (Resolution Information Complexity)}, a \textbf{solver-observable empirical proxy} intended to capture proof-theoretic signals from CDCL solver dynamics, together with a compression-based approximation of time-bounded descriptive complexity. Unlike purely structural measures, RIC is derived from an algorithmic trace of solving rather than static graph properties.

On a benchmark of \textbf{653 satisfiable random 3-SAT instances}, we find that:
\begin{itemize}
    \item RIC exhibits ultra-low correlation with treewidth ($\rho = -0.218$).
    \item RIC achieves standalone predictive power of $R^2 = 13.90\%$.
    \item Combining RIC with treewidth improves prediction from $R^2 = 25.29\%$ to $R^2 = 35.36\%$ (+39.8\% relative improvement).
\end{itemize}

\textbf{Epistemic positioning:} RIC is \textbf{not} presented as a formal complexity measure or proof-theoretic invariant; it is positioned as a tractable proxy supported by empirical validation. We additionally include a small crafted calibration set for qualitative analysis only.
\end{abstract}

\begin{IEEEkeywords}
SAT hardness prediction, proof complexity, solver dynamics, Kolmogorov complexity, treewidth, information theory
\end{IEEEkeywords}

% ----------------------------
% 1. Introduction
% ----------------------------
\section{Introduction}

The Boolean satisfiability problem (SAT) lies at the heart of computational complexity theory and automated reasoning. While SAT is NP-complete in the worst case, practical instances exhibit enormous variance in solving difficulty. Predicting instance hardness \emph{a priori} remains a fundamental challenge with applications ranging from algorithm selection to benchmark design.

\subsection{The Dominance of Structural Measures}

Current hardness prediction approaches predominantly rely on \emph{structural} properties of the constraint graph: treewidth~\cite{bodlaender1998}, backdoor sets~\cite{williams2003}, community structure~\cite{newsham2014}, and clause-variable incidence patterns. These measures have achieved notable success in predicting solver performance.

However, a persistent limitation is that many structural measures are often \textbf{highly correlated} in practice (commonly reported as $\rho>0.95$ on certain benchmarks)~\cite{ansotegui2009}. As a result, combining many structural features can yield diminishing returns: the feature set may largely measure the same underlying dimension of topology.

\subsection{The Missing Dimension: Proof-Theoretic Signals}

Proof complexity theory~\cite{cook1979,haken1985} provides a complementary perspective: hardness is tied to the \emph{length and structure of proofs} in propositional proof systems. Resolution proof size, DRAT proof length, and related measures offer theoretical insight, but are typically defined most cleanly for UNSAT instances and are commonly available only \emph{post hoc}.

We ask: \textbf{Can we design a practical, computable proxy that captures proof-theoretic signals while remaining empirically independent of structural properties?}

\subsection{Our Contribution: RIC as a Proxy}

We introduce \textbf{Resolution Information Complexity (RIC)}, combining:
\begin{enumerate}
\item A compression-based approximation to time-bounded conditional Kolmogorov complexity, modeling witness (solution) description length relative to the instance.
\item A solver-dynamics proxy derived from CDCL statistics (conflicts, propagations, decisions), modeling proof-search effort.
\end{enumerate}

\textbf{Key empirical findings on 653 random 3-SAT instances:}
\begin{itemize}
\item \textbf{Independence:} RIC exhibits ultra-low correlation with treewidth ($\rho=-0.218$).
\item \textbf{Standalone performance:} $R^2=13.90\%$.
\item \textbf{Complementarity:} TW+RIC improves by +39.8\% over treewidth alone.
\end{itemize}

\subsection{Scope and Positioning}

We explicitly position RIC as a \textbf{solver-observable proxy} for proof-theoretic hardness rather than a formal complexity measure. This distinction is critical:

\begin{description}
\item[What RIC is:] An empirical tool that approximates proof-theoretic difficulty through computable features derived from solver behavior and compression heuristics.
\item[What RIC is not:] A rigorously defined complexity measure with provable bounds in a proof system or universal worst-case guarantees.
\end{description}

The present work focuses on \textbf{satisfiable (SAT)} instances. Extending RIC to \textbf{UNSAT} with proof-object analysis (e.g., DRAT traces) is essential future work.

\subsection{Paper Organization}

Section~\ref{sec:background} reviews related work. Section~\ref{sec:framework} defines the proxy framework. Section~\ref{sec:implementation} presents the practical computation. Section~\ref{sec:experiments} reports experiments. Section~\ref{sec:discussion} discusses implications and limitations.

% ----------------------------
% 2. Background & Related Work
% ----------------------------
\section{Background and Related Work}
\label{sec:background}

\subsection{Structural SAT Hardness Measures}

\paragraph{Treewidth.}
Treewidth~\cite{bodlaender1998} measures how ``tree-like'' a graph is. For SAT, the primal graph connects variables appearing together in clauses. Low treewidth enables efficient dynamic programming algorithms in certain settings~\cite{samer2010}. Exact computation is hard; heuristics are commonly used.

\paragraph{Backdoor sets.}
Backdoors~\cite{williams2003} are small variable sets whose assignment makes the residual formula tractable. Backdoor size can correlate with solver performance but is costly to compute exactly.

\paragraph{Community structure.}
Community modularity and clustering~\cite{newsham2014} capture variable community patterns and can be predictive on industrial instances.

\paragraph{Limitation: high intercorrelation.}
A key observation is that multiple structural measures can be highly correlated on some benchmarks~\cite{ansotegui2009}, suggesting redundancy and motivating orthogonal predictors.

\subsection{Proof Complexity}

\paragraph{Resolution.}
Resolution complexity~\cite{haken1985} lower-bounds DPLL-style solver effort for UNSAT refutations, with classic exponential lower bounds for pigeonhole and parity families.

\paragraph{DRAT proofs.}
Modern solvers can output DRAT proofs~\cite{heule2013} enabling checking and analysis, but typically after solving (post hoc).

\subsection{Kolmogorov Complexity in SAT}

\paragraph{Descriptive complexity.}
Kolmogorov complexity~\cite{livitanyi2008} is an ideal information measure, but is uncomputable. Practical work uses compression-based approximations.

\subsection{Empirical vs Formal Complexity}

The SAT community distinguishes between empirical predictors (used in solver portfolios and runtime prediction)~\cite{xu2008,hutter2014} and formal complexity measures tied to proof systems or worst-case guarantees~\cite{cook1979,haken1985}. RIC contributes to the empirical tradition while targeting proof-theoretic signals.

% ----------------------------
% 3. Framework
% ----------------------------
\section{The RIC Framework}
\label{sec:framework}

\subsection{Conceptual Definition (Idealized)}

Let $x\in\{0,1\}^*$ encode a SAT instance and $W(x)$ be the set of satisfying assignments. For a witness $y\in W(x)$ and time bound $t$, define an idealized quantity:
\[
\mathrm{RI}^t(x,y) := K^t(y\mid x) + J^t(\langle x,y\rangle),
\]
where:
\begin{itemize}
\item $K^t(y\mid x)$ is time-bounded conditional Kolmogorov complexity,
\item $J^t(\langle x,y\rangle)$ is a proof-search effort term (conceptually tied to proof systems / solver dynamics).
\end{itemize}

Then define:
\[
\mathrm{RIC}^t(x) := \min_{y\in W(x)} \mathrm{RI}^t(x,y).
\]

\begin{remark}[Computability]
The above definition is \emph{not computable} in general due to Kolmogorov complexity. This paper uses a practical approximation based on compression and solver statistics (Section~\ref{sec:implementation}).
\end{remark}

\subsection{Intuition}

\paragraph{Compression term.}
$K^t(y\mid x)$ models how much ``new information'' the witness contains beyond the instance.

\paragraph{Dynamics term.}
$J^t(\langle x,y\rangle)$ models proof-search effort reflected in solver dynamics.

\paragraph{Min over witnesses.}
Taking $\min_{y\in W(x)}$ aligns with SAT solving: finding \emph{any} satisfying assignment is sufficient.

% ----------------------------
% 4. Implementation
% ----------------------------
\section{Implementation}
\label{sec:implementation}

\subsection{Approximating $K^t(y\mid x)$ via Compression}

We approximate conditional complexity using compression with conditioning:
\[
K(y\mid x)\approx K(x,y)-K(x),
\]
implemented by LZMA.

\begin{algorithm}[h]
\caption{Approximate $K^{\mathrm{poly}}(y\mid x)$}
\begin{algorithmic}[1]
\STATE \textbf{Input:} instance $x$ (CNF), witness $y$
\STATE Encode $x,y$ as bitstrings $\mathbf{b}_x,\mathbf{b}_y$
\STATE Concatenate $\mathbf{c}\leftarrow \mathbf{b}_x\|\mathbf{b}_y$
\STATE $c_{\text{joint}}\leftarrow \mathrm{LZMA}(\mathbf{c})$
\STATE $c_x\leftarrow \mathrm{LZMA}(\mathbf{b}_x)$
\STATE $\Delta\leftarrow (|c_{\text{joint}}|-|c_x|)\times 8$
\STATE \textbf{if} $\Delta<0$ \textbf{then} $\Delta\leftarrow 0$
\STATE \textbf{return} $K^{\mathrm{poly}}(y\mid x)\approx \Delta$
\end{algorithmic}
\end{algorithm}

\subsection{Approximating Proof-Theoretic Effort via Solver Statistics}

To minimize degrees of freedom, we define a base proxy with unit weights:
\[
J^{\mathrm{poly}}(x) = \log_2(1+c) + \log_2(1+p) + \log_2(1+d),
\]
where $c,p,d$ are conflicts, propagations, decisions.

\paragraph{Optional enhanced scaling (heuristic).}
If you keep your previous enhanced variant, treat it explicitly as heuristic:
\[
J^{\mathrm{enhanced}} = J^{\mathrm{poly}}\cdot \phi_{\text{size}}\cdot \phi_{\text{phase}}.
\]
In this v2 positioning, we recommend reporting the base version as primary, and any enhanced variant as a transparent heuristic.

\subsection{Complete RIC Computation}

\begin{algorithm}[h]
\caption{Compute RIC (SAT-only setting)}
\begin{algorithmic}[1]
\STATE \textbf{Input:} CNF $F$, timeout $t$
\STATE Run CDCL solver: obtain SAT witness $y$ and stats $(c,p,d)$
\IF{$F$ is SAT}
\STATE $K^{\mathrm{poly}}\leftarrow$ Algorithm 1$(F,y)$
\STATE $J^{\mathrm{poly}}\leftarrow \log_2(1+c)+\log_2(1+p)+\log_2(1+d)$
\STATE \textbf{return} $\mathrm{RIC}(F)=K^{\mathrm{poly}}+J^{\mathrm{poly}}$
\ELSE
\STATE \textbf{return} undefined (SAT-only scope)
\ENDIF
\end{algorithmic}
\end{algorithm}

% ----------------------------
% 5. Experiments
% ----------------------------
\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Benchmark and Setup}

\paragraph{Random 3-SAT instances (primary).}
We generated random 3-CNF formulas with $n\in\{50,75,100,150\}$ and ratios near the phase transition region ($m/n\approx 4.267$). After solving and filtering, we retained \textbf{653 satisfiable instances} for analysis.

\paragraph{Crafted instances (qualitative calibration only).}
We include a small crafted set ($n=10$) only as a sanity check; we do not draw quantitative conclusions from it.

\paragraph{Targets and predictors.}
We predict $\log_{10}(\mathrm{time}(F)+10^{-6})$ using treewidth (TW) and RIC (and combinations).

\subsection{Results: Random 3-SAT}

\begin{table}[h]
\centering
\caption{Prediction performance on random 3-SAT (n=653)}
\label{tab:random-models}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{$R^2$ (test)} & \textbf{Rel.\ Improvement} \\
\midrule
Treewidth only & 25.29\% & -- \\
RIC only       & 13.90\% & -- \\
TW + RIC       & \textbf{35.36\%} & \textbf{+39.8\%} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Independence analysis.}
Spearman correlation between RIC and treewidth:
\[
\rho=-0.218 \quad (p=1.12\times 10^{-4}).
\]

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{figures/fig1_models.png}
\caption{Model performance comparison (random instances).}
\label{fig:models}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{figures/fig2_correlation.png}
\caption{RIC--Treewidth independence on random instances ($\rho=-0.218$).}
\label{fig:correlation}
\end{figure}

\subsection{Crafted Instances (Qualitative Only)}

We report crafted results only to illustrate sensitivity to proof-hard families; the sample size is too small for quantitative claims.

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{figures/fig3_scatter.png}
\caption{Scatter illustration (crafted set used qualitatively).}
\label{fig:scatter}
\end{figure}

% ----------------------------
% 6. Discussion
% ----------------------------
\section{Discussion}
\label{sec:discussion}

\subsection{Why RIC Can Be Orthogonal to Structural Measures}

Treewidth captures structural decomposability, while RIC is derived from solver-observable dynamics and compression heuristics. The observed low correlation suggests these can capture complementary information.

\subsection{On ``Measure'' vs ``Proxy'': Epistemic Positioning}

A \emph{complexity measure} is a formal object with provable bounds and system-level meaning. An \emph{empirical proxy} is a computable approximation validated by experiments. RIC falls in the latter category in this paper.

\subsection{Limitations}

\paragraph{SAT-only scope.}
We do not analyze UNSAT instances in this version. Extending to UNSAT with DRAT proof analysis is future work.

\paragraph{Approximation quality.}
Compression-based approximations and solver statistics are heuristics; their theoretical relationship to proof complexity is not established here.

% ----------------------------
% 7. Conclusion
% ----------------------------
\section{Conclusion}

We introduced \textbf{RIC}, a solver-observable proxy intended to capture proof-theoretic signals beyond structural measures. On 653 random 3-SAT instances, RIC shows ultra-low correlation with treewidth ($\rho=-0.218$) and improves prediction when combined with treewidth (+39.8\% relative improvement). RIC is positioned as a foundation contribution and a practical proxy rather than a formal complexity measure.

\section*{Acknowledgments}

This research was conducted independently without external funding.

% ----------------------------
% Bibliography
% ----------------------------
\bibliographystyle{IEEEtran}
\begin{thebibliography}{10}

\bibitem{bodlaender1998}
H.~L. Bodlaender,
``A tourist guide through treewidth,''
\emph{Acta Cybernetica}, vol. 11, no. 1-2, pp. 1--21, 1993.

\bibitem{williams2003}
R.~Williams, C.~P. Gomes, and B.~Selman,
``Backdoors to typical case complexity,''
in \emph{Proc. IJCAI}, 2003, pp. 1173--1178.

\bibitem{newsham2014}
Z.~Newsham, V.~Ganesh, S.~Fischmeister, G.~Audemard, and L.~Simon,
``Impact of community structure on SAT solver performance,''
in \emph{Proc. SAT}, 2014, pp. 252--268.

\bibitem{cook1979}
S.~A. Cook and R.~A. Reckhow,
``The relative efficiency of propositional proof systems,''
\emph{Journal of Symbolic Logic}, vol. 44, no. 1, pp. 36--50, 1979.

\bibitem{haken1985}
A.~Haken,
``The intractability of resolution,''
\emph{Theoretical Computer Science}, vol. 39, pp. 297--308, 1985.

\bibitem{heule2013}
M.~J. Heule, W.~A. Hunt Jr, and N.~Wetzler,
``Trimming while checking clausal proofs,''
in \emph{Proc. FMCAD}, 2013, pp. 181--188.

\bibitem{livitanyi2008}
M.~Li and P.~M. Vit{\'a}nyi,
\emph{An Introduction to Kolmogorov Complexity and Its Applications},
3rd~ed.\ Springer, 2008.

\bibitem{samer2010}
M.~Samer and S.~Szeider,
``Algorithms for propositional model counting,''
\emph{Journal of Discrete Algorithms}, vol. 8, no. 1, pp. 50--64, 2010.

\bibitem{ansotegui2009}
C.~Ans{\'o}tegui, M.~L. Bonet, and J.~Levy,
``On the structure of industrial SAT instances,''
in \emph{Proc. CP}, 2009, pp. 127--141.

\bibitem{xu2008}
L.~Xu, F.~Hutter, H.~H. Hoos, and K.~Leyton-Brown,
``SATzilla: Portfolio-based algorithm selection for SAT,''
\emph{Journal of Artificial Intelligence Research}, vol. 32, pp. 565--606, 2008.

\bibitem{hutter2014}
F.~Hutter, L.~Xu, H.~H. Hoos, and K.~Leyton-Brown,
``Algorithm runtime prediction: Methods \& evaluation,''
\emph{Artificial Intelligence}, vol. 206, pp. 79--111, 2014.

\end{thebibliography}

\end{document}
