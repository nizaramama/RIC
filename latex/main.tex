\documentclass[11pt]{article}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{caption}
\usepackage{url}

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

% ============================================================================
% GRAPHICS PATH
% main.tex is in latex/, figures are in figures/
% ============================================================================
\graphicspath{{../figures/}}

% ============================================================================
% HYPERREF SETUP
% ============================================================================
\hypersetup{
    pdftitle={RIC: A Solver-Observable Proxy for Proof-Theoretic SAT Hardness},
    pdfauthor={Nizar Amama},
    pdfsubject={SAT hardness, proof complexity, solver dynamics},
    pdfkeywords={SAT, hardness prediction, proof complexity, Kolmogorov complexity, treewidth},
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% ============================================================================
% CUSTOM COMMANDS
% ============================================================================
\newcommand{\RIC}{\textsc{RIC}}
\newcommand{\SAT}{\textsc{SAT}}
\newcommand{\UNSAT}{\textsc{UNSAT}}
\newcommand{\CDCL}{\textsc{CDCL}}

% ============================================================================
% TITLE AND AUTHOR
% ============================================================================
\title{\textbf{RIC: A Solver-Observable Proxy for\\Proof-Theoretic SAT Hardness}}

\author{
    Nizar Amama\\
    Independent Researcher\\
    \texttt{amamanizar@gmail.com}\\
    ORCID: \href{https://orcid.org/0009-0004-6721-1117}{0009-0004-6721-1117}
}

\date{}

% ============================================================================
% DOCUMENT
% ============================================================================
\begin{document}

\maketitle

\noindent
\textbf{Preprint DOI:} \href{https://doi.org/10.5281/zenodo.17970752}\\
\textbf{GitHub:} \url{https://github.com/nizaramama/RIC}

\vspace{1em}

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
Structural hardness measures for Boolean satisfiability—treewidth, backdoor size, community structure—typically exhibit high mutual correlation ($\rho > 0.95$), capturing essentially the same underlying dimension of constraint graph topology. This redundancy limits their collective discriminative power for instance hardness characterization.

We introduce \textbf{\RIC{} (Resolution Information Complexity)}, a solver-observable proxy that combines time-bounded Kolmogorov complexity with \CDCL{} solver dynamics to approximate proof-theoretic hardness. Unlike structural measures, \RIC{} operates on the algorithmic trace of the solving process rather than static graph properties.

On a benchmark of 653 satisfiable random 3-\SAT{} instances, we find that: (1) \RIC{} exhibits ultra-low correlation with treewidth ($\rho = -0.218$), compared to typical $\rho > 0.95$ among structural measures; (2) \RIC{} achieves standalone predictive power of $R^2 = 13.90\%$; and (3) combining \RIC{} with treewidth improves prediction by $+39.8\%$ relative gain ($R^2 = 35.36\%$).

\RIC{} represents an empirical complement to structural complexity. While not a formal complexity measure, it provides a practical approximation to proof-theoretic difficulty with implications for solver portfolios and hardness characterization.

\textbf{Keywords:} Boolean satisfiability, proof complexity, CDCL solvers, Kolmogorov complexity, hardness prediction
\end{abstract}

% ============================================================================
% SECTION 1: INTRODUCTION
% ============================================================================
\section{Introduction}

Predicting the computational hardness of Boolean satisfiability (\SAT{}) instances is fundamental to solver design, automated reasoning, and complexity theory. Most existing approaches rely on \emph{structural measures}—treewidth, backdoor size, community modularity—which quantify properties of the constraint graph topology. However, these measures typically exhibit extremely high mutual correlation ($\rho > 0.95$), effectively capturing the same underlying dimension. This redundancy limits their collective explanatory power: combining correlated features yields diminishing returns.

The question arises: \emph{does there exist an orthogonal dimension of \SAT{} hardness independent of graph structure?}

\subsection{Main Contribution}

We introduce \textbf{\RIC{} (Resolution Information Complexity)}, a solver-observable proxy that combines time-bounded Kolmogorov complexity with Conflict-Driven Clause Learning (\CDCL{}) solver dynamics. Unlike structural measures, \RIC{} operates on the \emph{algorithmic trace} of the solving process—conflicts, propagations, learned clause activity—rather than static graph properties.

On 653 random 3-\SAT{} instances, we demonstrate:
\begin{enumerate}
    \item \textbf{Orthogonality}: \RIC{} exhibits ultra-low correlation with treewidth ($\rho = -0.218$), establishing it as a genuinely independent dimension
    \item \textbf{Predictive utility}: Standalone $R^2 = 13.90\%$, with combined model achieving $R^2 = 35.36\%$ (+39.8\% improvement)
    \item \textbf{Computational tractability}: \RIC{} is efficiently computable via standard \CDCL{} solvers and compression algorithms
\end{enumerate}

\subsection{Scope and Positioning}

\textbf{We explicitly position \RIC{} as a solver-observable empirical proxy for proof-theoretic hardness rather than a formal complexity measure.}

\begin{description}[leftmargin=2.5cm, style=nextline]
\item[\textbf{What \RIC{} is:}] A computable proxy that approximates proof-theoretic difficulty through \CDCL{} solver dynamics and compression-based estimates of information content. \RIC{} provides practical hardness characterization validated through correlation and predictive utility.

\item[\textbf{What \RIC{} is not:}] A formally defined complexity measure with provable worst-case bounds, completeness guarantees, or axiomatic foundations. \RIC{} does not constitute a proof technique for complexity class separation.

\item[\textbf{Current scope:}] This work focuses exclusively on \emph{satisfiable} (\SAT{}) instances. Extending \RIC{} to unsatisfiable (\UNSAT{}) instances with DRAT proof analysis is essential future work where proof complexity is more directly observable.
\end{description}

\subsection{Significance}

The existence of an orthogonal dimension to structural complexity has several implications:
\begin{itemize}
    \item \textbf{Theoretical}: Demonstrates that graph topology alone does not fully characterize \SAT{} hardness; proof-theoretic properties constitute an independent axis
    \item \textbf{Practical}: Enables improved solver portfolios and instance selection by combining complementary features
    \item \textbf{Methodological}: Establishes a template for developing hybrid hardness measures
\end{itemize}

% ============================================================================
% SECTION 2: RELATED WORK
% ============================================================================
\section{Related Work}
\label{sec:related}

\subsection{Structural Hardness Measures}

Most \SAT{} hardness prediction approaches employ features derived from constraint graph structure. Treewidth of the primal graph has been extensively studied, with small treewidth enabling efficient dynamic programming algorithms. Backdoor sets—subsets of variables whose instantiation renders the residual formula tractable—correlate with hardness but are expensive to find. Community structure measures quantify graph decomposability. A consistent finding is \emph{extremely high mutual correlation} ($\rho > 0.95$), suggesting these measures capture essentially the same dimension.

\subsection{Proof Complexity}

Resolution complexity studies the difficulty of refuting unsatisfiable formulas via resolution proof systems. Resolution width connects structural properties to proof size, but is primarily defined for \UNSAT{} instances. Modern \CDCL{} solvers implicitly construct resolution-based proofs, with DRAT format enabling explicit verification for \UNSAT{} instances. For satisfiable instances, proof complexity is less well-defined—our work addresses this gap.

\subsection{Kolmogorov Complexity in SAT}

Kolmogorov complexity has been applied to \SAT{} in limited contexts, including entropy-based arguments for the phase transition and observations that easier instances tend to have more compressible representations. Our contribution is the first systematic integration of time-bounded Kolmogorov complexity with \CDCL{} dynamics into a computable hardness proxy.

\subsection{Positioning of RIC}

\RIC{} occupies a unique position: unlike structural measures, it captures proof-search dynamics; unlike pure runtime prediction, it has information-theoretic grounding; unlike resolution complexity, it applies to satisfiable instances; and unlike theoretical measures, it is practically computable. \RIC{} is best understood as a \emph{bridge} between structural graph theory and proof-theoretic complexity.

% ============================================================================
% SECTION 3: THE RIC FRAMEWORK
% ============================================================================
\section{The RIC Framework}
\label{sec:framework}

We present \RIC{} in two stages: first, the \emph{conceptual definition} motivating the design; second, the \emph{practical approximation} enabling computation.

\subsection{Preliminaries}

A formula in conjunctive normal form (CNF) is a conjunction of clauses, where each clause is a disjunction of literals. The satisfiability problem (\SAT{}) asks whether there exists a variable assignment satisfying all clauses. Conflict-Driven Clause Learning (\CDCL{}) is the dominant algorithm for modern \SAT{} solving, combining systematic search with unit propagation, conflict analysis, and clause learning.

\subsection{Conceptual Definition}

\subsubsection{Motivation: Information Content of Solutions}

Consider a satisfiable formula $\phi$ with solution $y \in W(\phi)$. The \emph{information content} of finding $y$ given $\phi$ can be decomposed as:

\begin{equation}
\text{Hardness}(\phi) \approx K(y \mid \phi) + J(\text{verification of } \langle \phi, y \rangle)
\end{equation}

where $K(y \mid \phi)$ is conditional Kolmogorov complexity and $J(\cdot)$ is the cost of verifying the solution.

\begin{definition}[Idealized RIC]
For a satisfiable formula $\phi$:
\begin{equation}
\RIC_{\text{ideal}}(\phi) = \min_{y \in W(\phi)} \left[ K(y \mid \phi) + J(\langle \phi, y \rangle) \right]
\end{equation}
\end{definition}

\begin{remark}[Uncomputability]
The idealized \RIC{} is \textbf{not computable} due to the undecidability of Kolmogorov complexity. This definition serves purely as conceptual motivation.
\end{remark}

\subsection{Practical Approximation}

\subsubsection{Approximating $K(y \mid \phi)$: Compression-Based Proxy}

We use time-bounded Kolmogorov complexity via LZMA compression:
\begin{equation}
K_{\text{poly}}(y \mid \phi) \approx \text{LZMA-compressed size of } y \text{ given context } \phi
\end{equation}

For satisfying assignment $y$: (1) serialize $\phi$ as byte sequence, (2) serialize $y$ as bit vector, (3) compress $y$ using LZMA with $\phi$ as dictionary context, (4) measure compressed size in bits.

\subsubsection{Approximating $J(\cdot)$: Solver-Observable Proxy}

Instead of analyzing verification proofs directly, we use \CDCL{} solver statistics:

\begin{definition}[Solver Statistics]
For a \CDCL{} run on $\phi$ finding solution $y$, collect:
\begin{itemize}
    \item $c$: Total conflicts encountered
    \item $p$: Total unit propagations performed
    \item $d$: Total decisions made
\end{itemize}
\end{definition}

\begin{definition}[Proof-Theoretic Proxy]
\begin{equation}
J_{\text{poly}}(c, p, d) = \log_2(1 + c) + \log_2(1 + p) + \log_2(1 + d)
\end{equation}
\end{definition}

The logarithmic scaling matches information-theoretic intuition, and equal weighting minimizes degrees of freedom.

\subsection{Unified Definition}

\begin{definition}[RIC - Practical]
For satisfiable formula $\phi$:
\begin{equation}
\boxed{\RIC(\phi) = K_{\text{poly}}(y \mid \phi) + J_{\text{poly}}(c, p, d)}
\end{equation}
where $y$ is the solution found by \CDCL{}, and $(c, p, d)$ are solver statistics.
\end{definition}

\begin{remark}[Solver Dependence]
\RIC{} depends on the specific \CDCL{} implementation. We mitigate this by using a standard solver (Glucose) with default settings and focusing on \emph{relative} hardness comparisons.
\end{remark}

% ============================================================================
% SECTION 4: IMPLEMENTATION
% ============================================================================
\section{Implementation}
\label{sec:implementation}

\subsection{Solver Setup}

We use Glucose 4, a state-of-the-art \CDCL{} solver, instrumented to log solver statistics. Single-threaded execution ensures reproducibility.

\subsection{Compression Pipeline}

Given solution $y$ for formula $\phi$ with $n$ variables:
\begin{enumerate}
    \item Represent $y$ as bit vector
    \item Convert to byte array
    \item Prepend with $\phi$ representation
    \item Apply LZMA compression with dictionary size 64 KB
    \item Measure compressed size in bits
\end{enumerate}

\subsection{RIC Computation}

\begin{enumerate}
    \item Run Glucose on $\phi$ to obtain $(y, c, p, d)$
    \item If \UNSAT, return $\infty$ or exclude
    \item Compute $K_{\text{poly}} \leftarrow \text{CompressedSize}(y, \phi)$
    \item Compute $J_{\text{poly}} \leftarrow \log_2(1+c) + \log_2(1+p) + \log_2(1+d)$
    \item Return $\RIC = K_{\text{poly}} + J_{\text{poly}}$
\end{enumerate}

\subsection{Computational Complexity}

Total complexity is dominated by \CDCL{} solving time; compression overhead is negligible ($<1\%$ in practice).

\subsection{Reproducibility}

Complete source code, data, and scripts available at: \url{https://github.com/nizaramama/RIC}

Archived snapshot: \href{https://doi.org/10.5281/zenodo.17968982}{10.5281/zenodo.17968982}

% ============================================================================
% SECTION 5: EXPERIMENTAL VALIDATION
% ============================================================================
\section{Experimental Validation}
\label{sec:experiments}

\subsection{Dataset}

\subsubsection{Random 3-SAT Benchmark}

We generated 653 satisfiable random 3-\SAT{} instances with variable count $n \in \{50, 75, 100, 150\}$ and clause-to-variable ratio $\alpha = 4.2$ (near phase transition threshold $\alpha_c \approx 4.267$).

Treewidth upper bounds computed using QuickBB. Target variable: $\log_{10}(\text{solving time})$ in seconds.

\subsection{Experimental Protocol}

\textbf{Train/Test Split:} 70\% training (457 instances), 30\% testing (196 instances), stratified by $n$.

\textbf{Metrics:} Pearson correlation $\rho$, Spearman $\rho_s$, $R^2$ on test set.

\textbf{Models:} (1) Treewidth-only, (2) \RIC{}-only, (3) Combined (TW + \RIC).

\subsection{Results}

\subsubsection{Orthogonality Analysis}

\begin{table}[h]
\centering
\caption{Correlation between \RIC{} and Treewidth}
\label{tab:correlation}
\begin{tabular}{lcc}
\toprule
Metric & Value & $p$-value \\
\midrule
Pearson $\rho$ & $-0.218$ & $1.12 \times 10^{-4}$ \\
Spearman $\rho_s$ & $-0.203$ & $4.58 \times 10^{-4}$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding 1:} \RIC{} exhibits ultra-low correlation with treewidth ($\rho = -0.218$), establishing orthogonality. Typical structural measures correlate at $\rho > 0.95$.

\subsubsection{Predictive Performance}

\begin{table}[h]
\centering
\caption{Regression Performance on Test Set}
\label{tab:regression}
\begin{tabular}{lccc}
\toprule
Model & $R^2$ & RMSE & $p$-value \\
\midrule
Treewidth only & 25.29\% & 0.487 & $< 10^{-6}$ \\
\RIC{} only & 13.90\% & 0.523 & $< 10^{-6}$ \\
Combined (TW + \RIC) & 35.36\% & 0.453 & $< 10^{-6}$ \\
\midrule
\textbf{Relative improvement} & \textbf{+39.8\%} & & \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding 2:} Combining \RIC{} with treewidth yields $R^2 = 35.36\%$, a \textbf{+39.8\% relative improvement} over treewidth alone.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{fig1_models.png}
\caption{Model performance comparison}
\label{fig:models}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{fig2_correlation.png}
\caption{RIC--treewidth correlation scatter plot}
\label{fig:correlation}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{fig3_scatter.png}
\caption{RIC vs treewidth scatter}
\label{fig:scatter}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{fig4_distribution.png}
\caption{RIC distribution across instance categories}
\label{fig:distribution}
\end{figure}

\subsection{Qualitative Analysis: Crafted Instances}

\textbf{Scope and Disclaimer:} We include 10 crafted instances as a \textbf{preliminary sanity check only}. Due to insufficient sample size, we make \textbf{no quantitative claims} from this set.

Observations: \RIC{} correctly ranks known hard families (Pigeonhole, parity, Tseitin) and responds differently than to random instances, confirming sensitivity to proof structure. Comprehensive evaluation on large crafted benchmarks remains essential future work.

% ============================================================================
% SECTION 6: DISCUSSION
% ============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{On Measures vs. Proxies: Epistemic Positioning}

A \textbf{complexity measure} possesses: (1) axiomatic foundation, (2) worst-case guarantees, (3) completeness, (4) invariance. Examples: resolution width, circuit depth, Kolmogorov complexity.

An \textbf{empirical proxy} is: (1) computable, (2) validated through correlation, (3) useful in practice, (4) approximate without formal guarantees. Examples: heuristic treewidth bounds, solver runtime features.

\textbf{RIC is a proxy, not a measure.} It provides computable approximations validated through correlation and predictive utility, but depends on solver implementation and lacks formal guarantees.

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{SAT-only focus}: We do not analyze \UNSAT{} proof objects (DRAT)
    \item \textbf{Compression proxy}: LZMA is crude; may miss conditional structure
    \item \textbf{Solver dependence}: $J(\cdot)$ depends on implementation
    \item \textbf{Benchmark bias}: Random 3-\SAT{} may not represent industrial distributions
    \item \textbf{Model simplicity}: Linear $R^2$ may understate nonlinear interactions
\end{enumerate}

\subsection{Broader Implications}

\RIC{}'s orthogonality suggests a general principle: \emph{complete hardness characterization requires multiple independent dimensions}.

Potential applications:
\begin{itemize}
    \item \textbf{Hybrid measures}: S3R = Spectral entropy + \RIC
    \item \textbf{Solver portfolios}: Use (\RIC, TW) for optimal solver selection
    \item \textbf{Instance generation}: Target high-\RIC{} instances for benchmarking
\end{itemize}

\subsection{Future Directions}

\textbf{Short-term:} (1) \UNSAT{} extension with DRAT, (2) crafted benchmarks ($n \geq 100$ per family), (3) solver comparison

\textbf{Medium-term:} (1) industrial instances, (2) hybrid S3R integration, (3) theoretical connection to resolution width

\textbf{Long-term:} (1) formal grounding, (2) extensions to SMT/CSP, (3) learned compression

% ============================================================================
% SECTION 7: CONCLUSION
% ============================================================================
\section{Conclusion}
\label{sec:conclusion}

We introduced \textbf{\RIC{} (Resolution Information Complexity)}, a solver-observable proxy for proof-theoretic \SAT{} hardness. On 653 random 3-\SAT{} instances, \RIC{} demonstrates:
\begin{enumerate}
    \item Ultra-low correlation with treewidth ($\rho = -0.218$)
    \item Standalone predictive power ($R^2 = 13.90\%$)
    \item +39.8\% improvement in combined models
\end{enumerate}

\RIC{} is explicitly positioned as an \textbf{empirical proxy}, not a formal measure. It demonstrates that proof-theoretic dynamics constitute a dimension largely orthogonal to structural complexity.

The most critical next steps: (1) extend to \UNSAT{} with DRAT, (2) validate on industrial benchmarks, (3) establish theoretical connections to proof complexity.

\RIC{} represents a foundation—a first step toward operationalizing proof-theoretic hardness in practical settings.

% ============================================================================
% BIBLIOGRAPHY
% ============================================================================
\begin{thebibliography}{10}

\bibitem{cook1971}
S. A. Cook, ``The complexity of theorem-proving procedures,'' \emph{Proc. ACM Symposium on Theory of Computing}, 1971.

\bibitem{haken1985}
A. Haken, ``The intractability of resolution,'' \emph{Theoretical Computer Science}, vol. 39, pp. 297--308, 1985.

\bibitem{bensasson2001}
E. Ben-Sasson and A. Wigderson, ``Short proofs are narrow—resolution made simple,'' \emph{Journal of the ACM}, vol. 48, no. 2, pp. 149--169, 2001.

\bibitem{marques1999}
J. P. Marques-Silva and K. A. Sakallah, ``GRASP: A search algorithm for propositional satisfiability,'' \emph{IEEE Transactions on Computers}, vol. 48, no. 5, pp. 506--521, 1999.

\bibitem{audemard2009}
G. Audemard and L. Simon, ``Predicting learnt clauses quality in modern SAT solvers,'' \emph{Proc. IJCAI}, 2009.

\bibitem{li2008}
M. Li and P. M. B. Vitányi, \emph{An Introduction to Kolmogorov Complexity and Its Applications}, Springer, 2008.

\bibitem{xu2008}
L. Xu, F. Hutter, H. H. Hoos, and K. Leyton-Brown, ``SATzilla: Portfolio-based algorithm selection for SAT,'' \emph{Journal of Artificial Intelligence Research}, vol. 32, pp. 565--606, 2008.

\bibitem{ansotegui2012}
C. Ansótegui, J. Giráldez-Cru, and J. Levy, ``The community structure of SAT formulas,'' \emph{Proc. SAT}, 2012.

\bibitem{heule2014}
M. J. H. Heule, W. A. Hunt Jr., and N. Wetzler, ``DRAT-trim: Efficient checking and trimming using expressive clausal proofs,'' \emph{Proc. SAT}, 2014.

\bibitem{gogate2004}
V. Gogate and R. Dechter, ``A complete anytime algorithm for treewidth,'' \emph{Proc. UAI}, 2004.

\end{thebibliography}

\end{document}
